{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import datetime\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.cluster import KMeans\n",
    "from datetime import timedelta, date\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare all file path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = \"../../../../Dataset/ukdale/\" + house + \"/labels.dat\"\n",
    "path_to_house = \"./house_2\"\n",
    "labels_file_path = path_to_house+\"/labels.dat\"\n",
    "time_csv_Path = path_to_house+\"/Time_CSV/Time_\"\n",
    "resampling_time_in_min = \"30min\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to get all channel file paths from the house directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_files(house_path):\n",
    "    \"\"\"\n",
    "    Get channel files from the house directory. \n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    house_path = Path to house folder/directory\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    filepath_array = Array of file paths \n",
    "    \n",
    "    \"\"\"\n",
    "    if(house_path[-1] != '/'):\n",
    "        house_path = house_path + '/'\n",
    "    filepath_array = []\n",
    "    for x in os.listdir(house_path):\n",
    "        if 'channel_' in x and x != \"channel_1.dat\":\n",
    "            filepath_array.append(house_path + x)\n",
    "    return filepath_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to read a channel file and add it to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_channel_file(filepath):\n",
    "    \"\"\"\n",
    "    This method reads channel file (.dat) using file path and returns a dataframe.\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    filepath = Path of the input channel (.dat) file\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    channel_df = Channel dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    channel_df = pd.read_csv(filepath, sep='\\\\s+', names=['Timestamp','Reading'], parse_dates=['Timestamp'], header=0)\n",
    "    return channel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to resample the channel usage in given time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling(input_df, time):\n",
    "    \"\"\"\n",
    "    This method takes channel usage dataframe and time interval as input \n",
    "    and resamples the data by the input time. \n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    input_df = Channel usage dataframe\n",
    "    time = time interval for resampling\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    final_data = Resampled dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    dataframe = input_df.set_index('Timestamp')\n",
    "    dataframe.index = pd.to_datetime(dataframe.index,unit = \"s\")\n",
    "    resample = dataframe.resample(time)\n",
    "    resampled_data = resample.mean()\n",
    "    final_data = resampled_data.reset_index()\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to resample and generate channel's on/off status data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resampled_dict(filepath_list, label_dict):\n",
    "    resampled_dict = {}\n",
    "    for file in filepath_list:\n",
    "        if('button' in file):\n",
    "            continue\n",
    "        df = read_channel_file(file)\n",
    "        resampled_data = resampling(df, resampling_time_in_min)\n",
    "        resampled_data = resampled_data.fillna(0)\n",
    "        filename = file.split('/')[-1].split('.')[0]\n",
    "        resampled_dict[label_dict[filename]] = resampled_data\n",
    "    return resampled_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to split datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_columns(df):\n",
    "    df['Timestamp'] = pd.to_datetime(df.Timestamp, format = '%Y-%m-%d %H:%M:%S')\n",
    "    for i in ([df]):\n",
    "        i['Date'] = i.Timestamp.dt.date\n",
    "        i['Time'] = i.Timestamp.dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to get labels from the labels.dat file of UK-Dale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(filepath):\n",
    "    \"\"\"\n",
    "    This method takes label file path as input and returns a dataframe with channel and appliance mappings\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    Label data file path.\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    Channel-Appliance name dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    labels_df = pd.read_csv(labels_file_path, sep='\\\\s+', names=['Channel_id','Appliance'])\n",
    "    labels_df[\"Channel_id\"] = [\"channel_\"+str(i) for i in range(1,labels_df.shape[0]+1)]\n",
    "    labels_dict = dict()\n",
    "    for row in labels_df.iterrows():\n",
    "        labels_dict[row[1][\"Channel_id\"]] = row[1][\"Appliance\"]\n",
    "    return labels_dict\n",
    "    # return labels_df, labels_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of channel files for a house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = get_labels(path_to_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_list = get_channel_files(path_to_house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample data, split datetime and create appliance wise dataframes of time and average values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df_dict = get_resampled_dict(filepath_list, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in label_dict.values():\n",
    "    if(val != 'aggregate'):\n",
    "        add_time_columns(resampled_df_dict[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_avg_df_dict = {}\n",
    "appliance_time_avg_df_dict = {}\n",
    "\n",
    "for val in label_dict.values():\n",
    "    if(val != 'aggregate'):\n",
    "        resampled_avg_df_dict[val]=resampled_df_dict[val].groupby('Time')['Reading'].mean()\n",
    "        \n",
    "for val in label_dict.values():\n",
    "    if(val != 'aggregate'):\n",
    "        times = list(resampled_avg_df_dict[val].index)\n",
    "        readings= list(resampled_avg_df_dict[val].values)\n",
    "        appliance_time_avg_df_dict[val] = pd.DataFrame({'Time':times,'Average':readings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  resampled_avg_df_dict['tv_dvd_digibox_lamp'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = list(resampled_avg_df_dict['laptop'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>7.499268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>6.277485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>5.523409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>01:30:00</td>\n",
       "      <td>4.164920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>3.585104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>02:30:00</td>\n",
       "      <td>2.667100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>1.529357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>03:30:00</td>\n",
       "      <td>0.607908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>0.477899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>04:30:00</td>\n",
       "      <td>0.493814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>0.614695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>05:30:00</td>\n",
       "      <td>1.283744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2.506415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>4.052813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>4.564551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>07:30:00</td>\n",
       "      <td>5.691017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>6.968129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>08:30:00</td>\n",
       "      <td>7.529005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>7.574186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>09:30:00</td>\n",
       "      <td>7.921864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>9.332266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>11.332178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>11.577827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>10.994448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>10.223829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>9.877014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>9.676024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>9.370008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>9.266996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>14:30:00</td>\n",
       "      <td>9.176161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>9.705873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>15:30:00</td>\n",
       "      <td>10.220377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>10.093554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>16:30:00</td>\n",
       "      <td>11.063480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>10.992959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>11.094086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>11.218508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>11.689029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>12.066982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>19:30:00</td>\n",
       "      <td>12.733932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>13.754245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>20:30:00</td>\n",
       "      <td>14.348442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>14.345384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>21:30:00</td>\n",
       "      <td>13.993829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>12.809992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>11.579906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>9.940175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>8.360611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time    Average\n",
       "0   00:00:00   7.499268\n",
       "1   00:30:00   6.277485\n",
       "2   01:00:00   5.523409\n",
       "3   01:30:00   4.164920\n",
       "4   02:00:00   3.585104\n",
       "5   02:30:00   2.667100\n",
       "6   03:00:00   1.529357\n",
       "7   03:30:00   0.607908\n",
       "8   04:00:00   0.477899\n",
       "9   04:30:00   0.493814\n",
       "10  05:00:00   0.614695\n",
       "11  05:30:00   1.283744\n",
       "12  06:00:00   2.506415\n",
       "13  06:30:00   4.052813\n",
       "14  07:00:00   4.564551\n",
       "15  07:30:00   5.691017\n",
       "16  08:00:00   6.968129\n",
       "17  08:30:00   7.529005\n",
       "18  09:00:00   7.574186\n",
       "19  09:30:00   7.921864\n",
       "20  10:00:00   9.332266\n",
       "21  10:30:00  11.332178\n",
       "22  11:00:00  11.577827\n",
       "23  11:30:00  10.994448\n",
       "24  12:00:00  10.223829\n",
       "25  12:30:00   9.877014\n",
       "26  13:00:00   9.676024\n",
       "27  13:30:00   9.370008\n",
       "28  14:00:00   9.266996\n",
       "29  14:30:00   9.176161\n",
       "30  15:00:00   9.705873\n",
       "31  15:30:00  10.220377\n",
       "32  16:00:00  10.093554\n",
       "33  16:30:00  11.063480\n",
       "34  17:00:00  10.992959\n",
       "35  17:30:00  11.094086\n",
       "36  18:00:00  11.218508\n",
       "37  18:30:00  11.689029\n",
       "38  19:00:00  12.066982\n",
       "39  19:30:00  12.733932\n",
       "40  20:00:00  13.754245\n",
       "41  20:30:00  14.348442\n",
       "42  21:00:00  14.345384\n",
       "43  21:30:00  13.993829\n",
       "44  22:00:00  12.809992\n",
       "45  22:30:00  11.579906\n",
       "46  23:00:00   9.940175\n",
       "47  23:30:00   8.360611"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appliance_time_avg_df_dict['laptop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary to save correct appliance name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_name_dict = dict()\n",
    "show_name_dict['laptop'] = \"Laptop\"\n",
    "show_name_dict['monitor'] = \"Monitor\"\n",
    "show_name_dict['speakers'] = \"Speakers\"\n",
    "show_name_dict['server'] = \"Server\"\n",
    "show_name_dict['router'] = \"Router\"\n",
    "show_name_dict['server_hdd'] = \"Server_hdd\"\n",
    "show_name_dict['kettle'] = \"Kettle\"\n",
    "show_name_dict['rice_cooker'] = \"Rice Cooker\"\n",
    "show_name_dict['running_machine'] = \"Running Machine\"\n",
    "show_name_dict['laptop2'] = \"Laptop2\"\n",
    "show_name_dict['washing_machine'] = \"Washing Machine\"\n",
    "show_name_dict['dish_washer'] = \"Dish Washer\"\n",
    "show_name_dict['fridge'] = \"Fridge\"\n",
    "show_name_dict['microwave'] = \"Microwave\"\n",
    "show_name_dict['toaster'] = \"Toaster\"\n",
    "show_name_dict['playstation'] = \"Playstation\"\n",
    "show_name_dict['modem'] = \"Modem\"\n",
    "show_name_dict['cooker'] = \"Cooker\"\n",
    "show_name_dict['electric_heater'] = \"Electric Heater\"\n",
    "show_name_dict['projector'] = \"Projector\"\n",
    "show_name_dict['tv_dvd_digibox_lamp'] = \"TV & DVD Digibox & Lamp\"\n",
    "show_name_dict['kettle_radio'] = \"Kettle & Radio\"\n",
    "show_name_dict['gas_boiler'] = \"Gas Boiler\"\n",
    "show_name_dict['freezer'] = \"Freezer\"\n",
    "show_name_dict['washing_machine_microwave_breadmaker'] = \"Washing Machine & Microwave & Breadmaker\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic to create dictionay of time to appliance values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = {}\n",
    "for time in times:\n",
    "    time_dict[time] = {}\n",
    "    for appliance in label_dict.values():\n",
    "        if(appliance != 'aggregate'):\n",
    "            df = appliance_time_avg_df_dict[appliance]\n",
    "            app = show_name_dict[appliance]\n",
    "            time_dict[time][app] = df.loc[df[\"Time\"]==time]['Average'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Laptop': 7.499268001615402,\n",
       " 'Monitor': 10.438064889879872,\n",
       " 'Speakers': 4.042233708376429,\n",
       " 'Server': 15.092855733053968,\n",
       " 'Router': 8.462483876929198,\n",
       " 'Server_hdd': 2.349382231303889,\n",
       " 'Kettle': 0.5855544931042072,\n",
       " 'Rice Cooker': 0.8384950057589917,\n",
       " 'Running Machine': 1.5774164357815255,\n",
       " 'Laptop2': 0.019210995559630496,\n",
       " 'Washing Machine': 2.7716389750937447,\n",
       " 'Dish Washer': 1.2612178277435275,\n",
       " 'Fridge': 38.92339668446003,\n",
       " 'Microwave': 0.359711716854574,\n",
       " 'Toaster': 0.23675755734850815,\n",
       " 'Playstation': 0.7727599648040582,\n",
       " 'Modem': 7.5228631857972905,\n",
       " 'Cooker': 0.0010800658056154238}"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_dict[times[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in times:\n",
    "    t = int(time.strftime(\"%H%M%S\"))\n",
    "    time_dict_df = pd.DataFrame(time_dict[time].items(),columns=['Appliance','Average'])\n",
    "    time_dict_df.to_csv(r''+time_csv_Path+str(t)+'.csv', header=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
