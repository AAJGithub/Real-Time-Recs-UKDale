{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0e710077f94d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "from datetime import timedelta, date\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_files(house_path):\n",
    "    \"\"\"\n",
    "    Get channel files from the house directory. \n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    house_path = Path to house folder/directory\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    filepath_array = Array of file paths \n",
    "    \n",
    "    \"\"\"\n",
    "    if(house_path[-1] != '/'):\n",
    "        house_path = house_path + '/'\n",
    "    filepath_array = []\n",
    "    for x in os.listdir(house_path):\n",
    "        if 'channel_' in x and x != \"channel_1.dat\":\n",
    "            filepath_array.append(house_path + x)\n",
    "    return filepath_array\n",
    "\n",
    "def read_channel_file(filepath):\n",
    "    \"\"\"\n",
    "    This method reads channel file (.dat) using file path and returns a dataframe.\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    filepath = Path of the input channel (.dat) file\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    channel_df = Channel dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    channel_df = pd.read_csv(filepath, sep='\\\\s+', names=['Timestamp','Reading'], parse_dates=['Timestamp'], header=0)\n",
    "    return channel_df\n",
    "\n",
    "def resampling(input_df, time):\n",
    "    \"\"\"\n",
    "    This method takes channel usage dataframe and time interval as input \n",
    "    and resamples the data by the input time. \n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    input_df = Channel usage dataframe\n",
    "    time = time interval for resampling\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    final_data = Resampled dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    dataframe = input_df.set_index('Timestamp')\n",
    "    dataframe.index = pd.to_datetime(dataframe.index,unit = \"s\")\n",
    "    resample = dataframe.resample(time)\n",
    "    resampled_data = resample.mean()\n",
    "    final_data = resampled_data.reset_index()\n",
    "    final_data = final_data.fillna(0)\n",
    "    return final_data\n",
    "\n",
    "def apply_kmeans(column):\n",
    "    \"\"\"\n",
    "    This method takes channel readings column as input and applies K-Means clustering algorithm\n",
    "    with 2 clusters - On/Off.  \n",
    "    \n",
    "    Input:    \n",
    "    column = 1-d array of readings\n",
    "    \n",
    "    Output:    \n",
    "    x = original column but reshaped\n",
    "    km = kmeans object\n",
    "    \n",
    "    \"\"\"\n",
    "    x = np.array(column)\n",
    "    km = KMeans(n_clusters=2)\n",
    "    res = km.fit(x.reshape(-1,1))\n",
    "    return x, km\n",
    "\n",
    "def get_clusters(x, km, timeindex):\n",
    "    \"\"\"\n",
    "    This method returns clusters resulted from the K-Means algorithm. \n",
    "    \n",
    "    Input:\n",
    "    x = Readings array\n",
    "    km = K-Means algo object\n",
    "    timeindex = list of timestamps\n",
    "    \n",
    "    Output:\n",
    "    cluster_1 = Cluster of timestamps when device is Off\n",
    "    cluster_2 = Cluster of timestamps when device is On\n",
    "    times = Array of On/Off sequence for an appliance\n",
    "    \n",
    "    \"\"\"\n",
    "    times_1 = []\n",
    "    times_2 = []\n",
    "    cluster_1 = []\n",
    "    cluster_2 = []\n",
    "    for i in range(len(km.labels_)):\n",
    "        if(km.labels_[i] == 0):\n",
    "            cluster_1.append(x[i])\n",
    "            times_1.append('0')\n",
    "            times_2.append(str(timeindex[i]))\n",
    "        else:\n",
    "            cluster_2.append(x[i])\n",
    "            times_1.append(str(timeindex[i]))\n",
    "            times_2.append('0')\n",
    "            \n",
    "    if cluster_1[0] < cluster_2[0]:\n",
    "        return cluster_1, cluster_2, times_1\n",
    "    if cluster_1[0] > cluster_2[0]:\n",
    "        return cluster_2, cluster_1, times_2\n",
    "    \n",
    "\n",
    "def get_counts(channel_id):\n",
    "    channel_data = np.load()\n",
    "    count = 0\n",
    "    for i in channel_data:\n",
    "        if i == '0':\n",
    "            count+=1\n",
    "    print(len(channel_data) - count)\n",
    "    print(count)        \n",
    "\n",
    "    \n",
    "def get_channel_on_off_data(filepath_list, output_files_location):\n",
    "    \"\"\"\n",
    "    This method iterates over each channel in the house,\n",
    "    resamples the input channel usage data, \n",
    "    categorizes each instance of resampled data into On/Off states,\n",
    "    creates an array from it and saves it into a .npy file\n",
    "\n",
    "    Input:\n",
    "\n",
    "    filepath_list = List of paths of the channel (.dat) files from any house.\n",
    "    resampling_time = String denoting the time interval for resampling (30min).\n",
    "    output_files_location = Location of output .npy files.\n",
    "\n",
    "    Returns:\n",
    "    Creates .npy files on the specified path\n",
    "    returns list of datetimes where appliance is ON and 0 if its OFF\n",
    "\n",
    "    \"\"\"\n",
    "    channel_status_dict = dict()\n",
    "    for file in filepath_list:\n",
    "        if('button' in file):\n",
    "            continue\n",
    "        df = read_channel_file(file)\n",
    "        resampled_data = resampling(df, resampling_time_in_min)\n",
    "        resampled_data = resampled_data.fillna(0)\n",
    "        x, km = apply_kmeans(resampled_data['Reading'])\n",
    "        cluster_1, cluster_2, times = get_clusters(x, km, resampled_data.Timestamp)\n",
    "        channel_name = file.split(\"/\")[-1][:-4]\n",
    "        channel_status_dict[channel_name] = times\n",
    "    return channel_status_dict\n",
    "\n",
    "def get_labels(filepath):\n",
    "    \"\"\"\n",
    "    This method takes label file path as input and returns a dataframe with channel and appliance mappings\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    Label data file path.\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    Channel-Appliance name dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    labels_df = pd.read_csv(filepath, sep='\\\\s+', names=['Channel_id','Appliance'])\n",
    "    labels_df[\"Channel_id\"] = [\"channel_\"+str(i) for i in range(1,labels_df.shape[0]+1)]\n",
    "    labels_dict = dict()\n",
    "    for row in labels_df.iterrows():\n",
    "        labels_dict[row[1][\"Channel_id\"]] = row[1][\"Appliance\"]\n",
    "    return labels_df, labels_dict\n",
    "\n",
    "def fit_channel_to_mains_timeframe(channel_data, datetime_range):\n",
    "    \"\"\"\n",
    "    This method fits all channels in given datetime range\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    channel_data = input channels \n",
    "    datetime_range = Time range\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    channel_statuses = return channels\n",
    "    \n",
    "    \"\"\"\n",
    "    channel_statuses = []\n",
    "    for datetime in datetime_range:\n",
    "        if(datetime in channel_data):\n",
    "            channel_statuses.append(1)\n",
    "        else:\n",
    "            channel_statuses.append(0)\n",
    "    return channel_statuses\n",
    "\n",
    "def read_mains_data(mains_filepath, house):\n",
    "    \"\"\"\n",
    "    This method reads mains data of house\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    Mains data file path.\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    Mains dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Reading Mains Data\")\n",
    "    if house == 3 or house == 4:\n",
    "        mains_df = pd.read_csv(mains_filepath, sep='\\\\s+', names=['Timestamp','Reading_1'], parse_dates=['Timestamp'], header=0)\n",
    "    else:\n",
    "        mains_df = pd.read_csv(mains_filepath, sep='\\\\s+', names=['Timestamp','Reading_1','Reading_2','Reading_3'], parse_dates=['Timestamp'], header=0)\n",
    "    return mains_df\n",
    "\n",
    "\n",
    "def get_appliances_from_channels(list_of_channels, labels_df):\n",
    "    \"\"\"\n",
    "    This method returns a list of appliance names given a list of channels.\n",
    "    \n",
    "    Input:\n",
    "    list_of_channels = List of channels for which names to be extracted.\n",
    "    labels_df = Dataframe of channel ids and appliance names.\n",
    "    \n",
    "    Output:\n",
    "    List of appliance names corresponding to each channel in list_of_channels\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for item in list_of_channels:\n",
    "        result.append(labels_df.set_index('Channel_id').at[item, 'Appliance'])\n",
    "    return result\n",
    "\n",
    "def get_channel_list(house_path):\n",
    "    \"\"\"\n",
    "    This method gets the list of channels from the house directory.\n",
    "    \n",
    "    Input:\n",
    "    house_path = path to the house directory.\n",
    "    \n",
    "    Output:\n",
    "    channel_list = list of all the channels except channel_1 (mains).\n",
    "    \"\"\"\n",
    "    if(house_path[-1] != '/'):\n",
    "        house_path = house_path + '/'\n",
    "    channel_list = []\n",
    "    for item in os.listdir(house_path):\n",
    "        if 'channel_' in item and 'button' not in item and item != \"channel_1.dat\":\n",
    "            channel_list.append(item[:-4])\n",
    "    return channel_list\n",
    "\n",
    "def apply_day_type(df):\n",
    "    temp2 = df['Timestamp'].apply(add_day_type)\n",
    "    df['Weekend'] = temp2\n",
    "    \n",
    "def convert_decimal(binary_str):\n",
    "    return int(binary_str, 2)\n",
    "\n",
    "def weekday_status(time):\n",
    "    \"\"\"\n",
    "    This method returns if the given timestamp is a weekday or not\n",
    "    \n",
    "    Input:\n",
    "    Timestamp \n",
    "    \n",
    "    Output:\n",
    "    return status as 1 if weekday or 0 if weekend \n",
    "    \"\"\"\n",
    "    day_number=time.dayofweek\n",
    "    if day_number == 5 or day_number == 6:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def get_hour(time):\n",
    "    \"\"\"\n",
    "    This method returns hour data from datetime \n",
    "    \n",
    "    Input:\n",
    "    Datetime \n",
    "    \n",
    "    Output:\n",
    "    Hour data\n",
    "    \"\"\"\n",
    "    return time.hour\n",
    "\n",
    "def get_min(time):\n",
    "    \"\"\"\n",
    "    This method returns minute data from datetime \n",
    "    \n",
    "    Input:\n",
    "    Datetime \n",
    "    \n",
    "    Output:\n",
    "    Minute data\n",
    "    \"\"\"\n",
    "    return time.minute\n",
    "\n",
    "def get_sec(time):\n",
    "    \"\"\"\n",
    "    This method returns second data from datetime \n",
    "    \n",
    "    Input:\n",
    "    Datetime\n",
    "    \n",
    "    Output:\n",
    "    Second data\n",
    "    \"\"\"\n",
    "    return time.second\n",
    "\n",
    "def get_binary(target, length):\n",
    "    \"\"\"\n",
    "    This method returns if binary equivalent of target decimal value with given length\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    target: Decimal value\n",
    "    length: length of binary needed\n",
    "    \n",
    "    Output:\n",
    "    binary equivalent of target decimal value with given length\n",
    "    \"\"\"\n",
    "    target_len= '{0:0'+str(length)+'b}'\n",
    "    return [int(target) for target in list(target_len.format(target))]\n",
    "\n",
    "\n",
    "def get_dates_list(min_date, max_date):\n",
    "    \"\"\"\n",
    "    This method finds the dates between a given set of dates.\n",
    "    \n",
    "    Input:\n",
    "    date1 = Start date\n",
    "    date2 = End date\n",
    "    \n",
    "    Output:\n",
    "    List of date strings in between these dates\n",
    "    \"\"\"\n",
    "    Dates = []\n",
    "    start_dt = min_date\n",
    "    end_dt = max_date\n",
    "    for dt in daterange(start_dt, end_dt):\n",
    "        Dates.append(dt.strftime(\"%Y-%m-%d\"))\n",
    "    return Dates\n",
    "\n",
    "def daterange(date1, date2):\n",
    "    \"\"\"\n",
    "    This method finds the dates between a given set of dates.\n",
    "    \n",
    "    Input:\n",
    "    date1 = Start date\n",
    "    date2 = End date\n",
    "    \n",
    "    Output:\n",
    "    List of dates in between these dates\n",
    "    \"\"\"\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)\n",
    "        \n",
    "def divide_data_into_time(times, apriori_data):\n",
    "    \"\"\"\n",
    "    This method seperates ON appliance sequences by time and Saves them in a dictionary with time slices as the key\n",
    "    \n",
    "    Input:\n",
    "    times = List of time slices.\n",
    "    apriori_data = Output of the data_extractor().\n",
    "    \n",
    "    Output:\n",
    "    Dataframe of support and frequent itemsets.\n",
    "    \"\"\"\n",
    "    time_sequence_dict = dict()\n",
    "    for timestamp in times:\n",
    "        sequence_list = []\n",
    "        for data in apriori_data:\n",
    "            if timestamp in data:\n",
    "                sequence_list.append(data)\n",
    "        time_sequence_dict[timestamp] = sequence_list\n",
    "    return time_sequence_dict\n",
    "\n",
    "def get_support_and_itemsets(apriori_data, minimum_support):\n",
    "    \"\"\"\n",
    "    This method runs the apriori algorithm on the input data and returns frequent itemsets with their respective supports\n",
    "    \n",
    "    Input:\n",
    "    apriori_data = List-of-lists of appliances On at a particular time for each day.\n",
    "    minimum_support = Minimum support for getting the frequent itemsets.\n",
    "    \n",
    "    Output:\n",
    "    Dataframe of support and frequent itemsets\n",
    "    \"\"\"\n",
    "    te = TransactionEncoder()\n",
    "    data = te.fit(apriori_data).transform(apriori_data)\n",
    "    data = pd.DataFrame(data, columns = te.columns_)\n",
    "    return apriori(data, min_support = minimum_support, use_colnames = True)\n",
    "\n",
    "def get_channels_from_frequent_itemsets(frequent_itemsets_df):\n",
    "    \"\"\"\n",
    "    This method returns the set of unique channels present in the support-frequent itemsets dataframe.\n",
    "    This method was used to check the appliance coverage.\n",
    "    \n",
    "    Input:\n",
    "    frequent_itemsets_df = Dataframe of support and frequent itemsets.\n",
    "    \n",
    "    Output:\n",
    "    Set of channels present in the entire frequent itemsets\n",
    "    \"\"\"\n",
    "    channels = set()\n",
    "    for item in frequent_itemsets_df.itemsets:\n",
    "        for entry in list(item):\n",
    "            channels.add(entry)\n",
    "    return channels\n",
    "\n",
    "def get_appliances_from_channels(list_of_channels, labels_df):\n",
    "    \"\"\"\n",
    "    This method returns a list of appliance names given a list of channels.\n",
    "    \n",
    "    Input:\n",
    "    list_of_channels = List of channels for which names to be extracted.\n",
    "    labels_df = Dataframe of channel ids and appliance names.\n",
    "    \n",
    "    Output:\n",
    "    List of appliance names corresponding to each channel in list_of_channels\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for item in list_of_channels:\n",
    "        result.append(labels_df.set_index('Channel_id').at[item, 'Appliance'])\n",
    "    return result\n",
    "\n",
    "def get_channels_from_rules(rule_df):\n",
    "    \"\"\"\n",
    "    This method returns the set of unique channels present in the time-rules dataframe.\n",
    "    This method was used to check the appliance coverage.\n",
    "    \n",
    "    Input:\n",
    "    rules_df = Dataframe of time and appliances On.\n",
    "    \n",
    "    Output:\n",
    "    Set of channels present in the rules dataframe\n",
    "    \"\"\"\n",
    "    channel_list = []\n",
    "    for sequence in rule_df['consequents']:\n",
    "        list_of_channels = str(sequence)[12:-3].replace(\"'\",'').split(\", \")\n",
    "        for item in list_of_channels:\n",
    "            if item not in channel_list:\n",
    "                channel_list.append(item)\n",
    "    return channel_list\n",
    "\n",
    "def get_missing_channel_list(rule_df, full_channel_set):\n",
    "    \"\"\"\n",
    "    This method returns the set of unique channels not present in the time-rules dataframe.\n",
    "    This method was used to check the appliance coverage.\n",
    "    \n",
    "    Input:\n",
    "    rules_df = Dataframe of time and appliances On.\n",
    "    full_channel_set = Set of complete channels in the house\n",
    "    \n",
    "    Output:\n",
    "    Set of channels not present in the rules dataframe\n",
    "    \"\"\"\n",
    "    channel_set = set()\n",
    "    for sequence in rule_df['consequents']:\n",
    "        list_of_channels = sequence[12:-3].replace(\"'\",'').split(\", \")\n",
    "        channel_set.update(list_of_channels)\n",
    "    result_1 = full_channel_set - channel_set\n",
    "    return result_1\n",
    "\n",
    "def change_names(recs, show_name_dict):\n",
    "    res = []\n",
    "    for item in recs:\n",
    "        res.append(show_name_dict[item])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_display_names_dict(labels_to_name_file):\n",
    "    display_names_dict = dict()\n",
    "    display_names_df = pd.read_csv(labels_to_name_file, names= [\"Labels\", \"Name\"], header = 0)\n",
    "    for index, row in display_names_df.iterrows():\n",
    "        display_names_dict[row.Labels] = row.Name\n",
    "    return display_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# House 2 Lables\n",
    "\n",
    "# show_name_dict = dict()\n",
    "# show_name_dict['laptop'] = \"Laptop\"\n",
    "# show_name_dict['monitor'] = \"Monitor\"\n",
    "# show_name_dict['speakers'] = \"Speakers\"\n",
    "# show_name_dict['server'] = \"Server\"\n",
    "# show_name_dict['router'] = \"Router\"\n",
    "# show_name_dict['server_hdd'] = \"Server_hdd\"\n",
    "# show_name_dict['kettle'] = \"Kettle\"\n",
    "# show_name_dict['rice_cooker'] = \"Rice Cooker\"\n",
    "# show_name_dict['running_machine'] = \"Running Machine\"\n",
    "# show_name_dict['laptop2'] = \"Laptop2\"\n",
    "# show_name_dict['washing_machine'] = \"Washing Machine\"\n",
    "# show_name_dict['dish_washer'] = \"Dish Washer\"\n",
    "# show_name_dict['fridge'] = \"Fridge\"\n",
    "# show_name_dict['microwave'] = \"Microwave\"\n",
    "# show_name_dict['toaster'] = \"Toaster\"\n",
    "# show_name_dict['playstation'] = \"Playstation\"\n",
    "# show_name_dict['modem'] = \"Modem\"\n",
    "# show_name_dict['cooker'] = \"Cooker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House : 2\n",
      "path_to_house : C:/Users/pagara/Documents/Assignment/ukdale/house_2/\n",
      "labels_file : C:/Users/pagara/Documents/Assignment/ukdale/house_2/labels.dat\n",
      "channel_status_data_dir : Channel_status_data/House_2\n",
      "mains_channel_filepath : C:/Users/pagara/Documents/Assignment/ukdale/house_2/mains.dat\n",
      "resampling_time_in_min : 2min\n",
      "Intermediate files directory : house2_intermediate/\n"
     ]
    }
   ],
   "source": [
    "house = 2\n",
    "\n",
    "print(\"House : \" + str(house))\n",
    "\n",
    "path_to_house = \"C:/Users/pagara/Documents/Assignment/ukdale/house_\" + str(house) + \"/\"\n",
    "labels_file = path_to_house + \"labels.dat\"\n",
    "channel_status_data_dir = \"Channel_status_data/House_\" + str(house)\n",
    "if house ==3 or house ==4:\n",
    "    mains_channel_filepath = path_to_house + \"channel_1.dat\"\n",
    "else: \n",
    "    mains_channel_filepath = path_to_house + \"mains.dat\"\n",
    "resampling_time_in_min = \"2min\"\n",
    "output_file_path = \"house\"+str(house)+\"/\"\n",
    "channel_list = get_channel_list(path_to_house)\n",
    "intermediate_file_path = \"house\"+str(house)+\"_intermediate/\"\n",
    "output_dir = \"XGBoost/house\"+str(house)+\"_final/\"\n",
    "labels_to_name_file = \"../Labels_to_name_files/House_\" + str(house) + \".csv\"\n",
    "\n",
    "if not os.path.exists(output_file_path):\n",
    "    os.makedirs(output_file_path)\n",
    "if not os.path.exists(channel_status_data_dir):\n",
    "    os.makedirs(channel_status_data_dir)\n",
    "if not os.path.exists(intermediate_file_path):\n",
    "    os.makedirs(intermediate_file_path)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)    \n",
    "    \n",
    "print(\"path_to_house : \" + path_to_house)\n",
    "print(\"labels_file : \" + labels_file)\n",
    "print(\"channel_status_data_dir : \" + channel_status_data_dir)\n",
    "print(\"mains_channel_filepath : \" + mains_channel_filepath)\n",
    "print(\"resampling_time_in_min : \" + resampling_time_in_min)\n",
    "print(\"Intermediate files directory : \" + intermediate_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_name_dict = get_display_names_dict(labels_to_name_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['channel_10',\n",
       " 'channel_11',\n",
       " 'channel_12',\n",
       " 'channel_13',\n",
       " 'channel_14',\n",
       " 'channel_15',\n",
       " 'channel_16',\n",
       " 'channel_17',\n",
       " 'channel_18',\n",
       " 'channel_19',\n",
       " 'channel_2',\n",
       " 'channel_3',\n",
       " 'channel_4',\n",
       " 'channel_5',\n",
       " 'channel_6',\n",
       " 'channel_7',\n",
       " 'channel_8',\n",
       " 'channel_9']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Mains Data\n",
      "Done resampling for mains file\n",
      "Done processing channel files\n",
      "Done for channel : channel_10\n",
      "Done for channel : channel_11\n",
      "Done for channel : channel_12\n",
      "Done for channel : channel_13\n",
      "Done for channel : channel_14\n",
      "Done for channel : channel_15\n",
      "Done for channel : channel_16\n",
      "Done for channel : channel_17\n",
      "Done for channel : channel_18\n",
      "Done for channel : channel_19\n",
      "Done for channel : channel_2\n",
      "Done for channel : channel_3\n",
      "Done for channel : channel_4\n",
      "Done for channel : channel_5\n"
     ]
    }
   ],
   "source": [
    "labels_df, labels_map = get_labels(labels_file)\n",
    "\n",
    "mains_data = read_mains_data(mains_channel_filepath, house)\n",
    "resampled_mains_data = resampling(mains_data, resampling_time_in_min)\n",
    "resampled_mains_data = resampled_mains_data.set_index('Timestamp')\n",
    "\n",
    "print(\"Done resampling for mains file\")\n",
    "\n",
    "filepath_list = get_channel_files(path_to_house)\n",
    "channel_status_dict = get_channel_on_off_data(filepath_list, output_file_path)\n",
    "\n",
    "print(\"Done processing channel files\")\n",
    "\n",
    "updated_channel_status_dict = dict()\n",
    "datetime_range = resampled_mains_data.index.astype('str')\n",
    "for channel in channel_status_dict.keys():\n",
    "    updated_channel_status_dict[channel] = fit_channel_to_mains_timeframe(channel_status_dict[channel], datetime_range)\n",
    "    print(\"Done for channel : \" + channel)\n",
    "\n",
    "for key in updated_channel_status_dict.keys():\n",
    "    filename = key + '.npy'\n",
    "    filepath = channel_status_data_dir + \"/\" + filename\n",
    "    np.save(filepath, updated_channel_status_dict[key])\n",
    "\n",
    "print(\"House \" + str(house) + \" finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampled Mains data dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reading_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:40:00</th>\n",
       "      <td>628.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:42:00</th>\n",
       "      <td>2684.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:44:00</th>\n",
       "      <td>822.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:46:00</th>\n",
       "      <td>576.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:48:00</th>\n",
       "      <td>2823.157895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Reading_1\n",
       "Timestamp                       \n",
       "2013-03-09 14:40:00   628.500000\n",
       "2013-03-09 14:42:00  2684.800000\n",
       "2013-03-09 14:44:00   822.684211\n",
       "2013-03-09 14:46:00   576.055556\n",
       "2013-03-09 14:48:00  2823.157895"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_mains_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe with all appliance status data and datetimerange as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channel_status_df = pd.DataFrame(updated_channel_status_dict, index = resampled_mains_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_mains_data.to_csv(intermediate_file_path+\"resampled_mains_data.csv\")\n",
    "all_channel_status_df.to_csv(intermediate_file_path+\"all_channel_status_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_mains_data=pd.read_csv(intermediate_file_path+\"resampled_mains_data.csv\", sep=',',parse_dates=['Timestamp'] ,header=0, index_col=\"Timestamp\")\n",
    "all_channel_status_df=pd.read_csv(intermediate_file_path+\"all_channel_status_df.csv\", sep=',',parse_dates=['Timestamp'], header=0, index_col=\"Timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reading_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:40:00</th>\n",
       "      <td>628.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:42:00</th>\n",
       "      <td>2684.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:44:00</th>\n",
       "      <td>822.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:46:00</th>\n",
       "      <td>576.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:48:00</th>\n",
       "      <td>2823.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:06:00</th>\n",
       "      <td>242.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:08:00</th>\n",
       "      <td>268.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:10:00</th>\n",
       "      <td>267.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:12:00</th>\n",
       "      <td>266.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:14:00</th>\n",
       "      <td>268.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148038 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Reading_1\n",
       "Timestamp                       \n",
       "2013-03-09 14:40:00   628.500000\n",
       "2013-03-09 14:42:00  2684.800000\n",
       "2013-03-09 14:44:00   822.684211\n",
       "2013-03-09 14:46:00   576.055556\n",
       "2013-03-09 14:48:00  2823.157895\n",
       "...                          ...\n",
       "2013-10-01 05:06:00   242.950000\n",
       "2013-10-01 05:08:00   268.368421\n",
       "2013-10-01 05:10:00   267.750000\n",
       "2013-10-01 05:12:00   266.947368\n",
       "2013-10-01 05:14:00   268.166667\n",
       "\n",
       "[148038 rows x 1 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_mains_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_4</th>\n",
       "      <th>channel_5</th>\n",
       "      <th>channel_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:40:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:42:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:44:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:46:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:48:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:06:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:10:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:12:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:14:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148038 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     channel_2  channel_3  channel_4  channel_5  channel_6\n",
       "Timestamp                                                                 \n",
       "2013-03-09 14:40:00          0          0          1          1          0\n",
       "2013-03-09 14:42:00          0          0          1          1          0\n",
       "2013-03-09 14:44:00          0          0          1          1          0\n",
       "2013-03-09 14:46:00          0          0          1          1          0\n",
       "2013-03-09 14:48:00          0          0          1          1          0\n",
       "...                        ...        ...        ...        ...        ...\n",
       "2013-10-01 05:06:00          0          0          0          1          0\n",
       "2013-10-01 05:08:00          0          0          0          1          0\n",
       "2013-10-01 05:10:00          0          0          0          1          0\n",
       "2013-10-01 05:12:00          0          0          0          1          0\n",
       "2013-10-01 05:14:00          0          0          0          1          0\n",
       "\n",
       "[148038 rows x 5 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_channel_status_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Target Value column using appliance on/off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channel_status_df=all_channel_status_df.astype(str)\n",
    "all_channel_status_df['Binary'] = all_channel_status_df.values.sum(axis=1)\n",
    "all_channel_status_df[\"Target\"]=all_channel_status_df.apply(lambda row: convert_decimal(row.Binary), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_4</th>\n",
       "      <th>channel_5</th>\n",
       "      <th>channel_6</th>\n",
       "      <th>Binary</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:40:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:42:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:44:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:46:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:48:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:06:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:10:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:12:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:14:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148038 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    channel_2 channel_3 channel_4 channel_5 channel_6 Binary  \\\n",
       "Timestamp                                                                      \n",
       "2013-03-09 14:40:00         0         0         1         1         0  00110   \n",
       "2013-03-09 14:42:00         0         0         1         1         0  00110   \n",
       "2013-03-09 14:44:00         0         0         1         1         0  00110   \n",
       "2013-03-09 14:46:00         0         0         1         1         0  00110   \n",
       "2013-03-09 14:48:00         0         0         1         1         0  00110   \n",
       "...                       ...       ...       ...       ...       ...    ...   \n",
       "2013-10-01 05:06:00         0         0         0         1         0  00010   \n",
       "2013-10-01 05:08:00         0         0         0         1         0  00010   \n",
       "2013-10-01 05:10:00         0         0         0         1         0  00010   \n",
       "2013-10-01 05:12:00         0         0         0         1         0  00010   \n",
       "2013-10-01 05:14:00         0         0         0         1         0  00010   \n",
       "\n",
       "                     Target  \n",
       "Timestamp                    \n",
       "2013-03-09 14:40:00       6  \n",
       "2013-03-09 14:42:00       6  \n",
       "2013-03-09 14:44:00       6  \n",
       "2013-03-09 14:46:00       6  \n",
       "2013-03-09 14:48:00       6  \n",
       "...                     ...  \n",
       "2013-10-01 05:06:00       2  \n",
       "2013-10-01 05:08:00       2  \n",
       "2013-10-01 05:10:00       2  \n",
       "2013-10-01 05:12:00       2  \n",
       "2013-10-01 05:14:00       2  \n",
       "\n",
       "[148038 rows x 7 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_channel_status_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate weekday, hour, minute, second data from mains power data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "if house == 3 or house == 4:\n",
    "    power_df= pd.DataFrame(resampled_mains_data[\"Reading_1\"])\n",
    "    power_df=power_df.rename(columns={\"Reading_1\": \"Power\"})\n",
    "else:\n",
    "    power_df= pd.DataFrame(resampled_mains_data[\"Reading_2\"])\n",
    "    power_df=power_df.rename(columns={\"Reading_2\": \"Power\"})\n",
    "\n",
    "power_df[\"Weekday\"]=power_df.apply(lambda row: weekday_status(row.name), axis=1)\n",
    "power_df[\"Hour\"]=power_df.apply(lambda row: int(get_hour(row.name)), axis=1)\n",
    "power_df[\"Minute\"]=power_df.apply(lambda row: int(get_min(row.name)), axis=1)\n",
    "power_df[\"Second\"]=power_df.apply(lambda row: int(get_sec(row.name)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Power</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Second</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:40:00</th>\n",
       "      <td>628.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:42:00</th>\n",
       "      <td>2684.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:44:00</th>\n",
       "      <td>822.684211</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:46:00</th>\n",
       "      <td>576.055556</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-09 14:48:00</th>\n",
       "      <td>2823.157895</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:06:00</th>\n",
       "      <td>242.950000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:08:00</th>\n",
       "      <td>268.368421</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:10:00</th>\n",
       "      <td>267.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:12:00</th>\n",
       "      <td>266.947368</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:14:00</th>\n",
       "      <td>268.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148038 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Power  Weekday  Hour  Minute  Second\n",
       "Timestamp                                                      \n",
       "2013-03-09 14:40:00   628.500000        0    14      40       0\n",
       "2013-03-09 14:42:00  2684.800000        0    14      42       0\n",
       "2013-03-09 14:44:00   822.684211        0    14      44       0\n",
       "2013-03-09 14:46:00   576.055556        0    14      46       0\n",
       "2013-03-09 14:48:00  2823.157895        0    14      48       0\n",
       "...                          ...      ...   ...     ...     ...\n",
       "2013-10-01 05:06:00   242.950000        1     5       6       0\n",
       "2013-10-01 05:08:00   268.368421        1     5       8       0\n",
       "2013-10-01 05:10:00   267.750000        1     5      10       0\n",
       "2013-10-01 05:12:00   266.947368        1     5      12       0\n",
       "2013-10-01 05:14:00   268.166667        1     5      14       0\n",
       "\n",
       "[148038 rows x 5 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset to 50% to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(power_df,all_channel_status_df[\"Target\"], test_size=0.5, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74019, 5)\n",
      "(74019, 5)\n",
      "(74019,)\n",
      "(74019,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate classifier and train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training on 50% data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on complete data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disintegrate data to appliance level data[Decimal to binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df= pd.DataFrame({\"Target\":y_pred}, index=y_test.index)\n",
    "pred_df[\"Appliance_Binary_data\"]=pred_df.apply(lambda row: get_binary(row.Target, len(channel_list)), axis=1)\n",
    "predicted_df=pd.DataFrame(pred_df[\"Appliance_Binary_data\"].to_list(), columns=channel_list, index=pred_df.index)\n",
    "# predicted_df=predicted_df.rename(columns=labels_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tv_dvd_digibox_lamp</th>\n",
       "      <th>kettle_radio</th>\n",
       "      <th>gas_boiler</th>\n",
       "      <th>freezer</th>\n",
       "      <th>washing_machine_microwave_breadmaker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-06-20 09:58:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-20 10:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-20 10:02:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-20 10:04:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-20 10:06:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:06:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:10:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:12:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:14:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74019 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tv_dvd_digibox_lamp  kettle_radio  gas_boiler  freezer  \\\n",
       "Timestamp                                                                     \n",
       "2013-06-20 09:58:00                    0             0           0        1   \n",
       "2013-06-20 10:00:00                    0             0           0        1   \n",
       "2013-06-20 10:02:00                    0             0           0        0   \n",
       "2013-06-20 10:04:00                    0             0           0        0   \n",
       "2013-06-20 10:06:00                    0             0           0        0   \n",
       "...                                  ...           ...         ...      ...   \n",
       "2013-10-01 05:06:00                    0             0           1        0   \n",
       "2013-10-01 05:08:00                    0             0           0        1   \n",
       "2013-10-01 05:10:00                    0             0           0        1   \n",
       "2013-10-01 05:12:00                    0             0           0        1   \n",
       "2013-10-01 05:14:00                    0             0           0        1   \n",
       "\n",
       "                     washing_machine_microwave_breadmaker  \n",
       "Timestamp                                                  \n",
       "2013-06-20 09:58:00                                     0  \n",
       "2013-06-20 10:00:00                                     0  \n",
       "2013-06-20 10:02:00                                     0  \n",
       "2013-06-20 10:04:00                                     0  \n",
       "2013-06-20 10:06:00                                     0  \n",
       "...                                                   ...  \n",
       "2013-10-01 05:06:00                                     0  \n",
       "2013-10-01 05:08:00                                     0  \n",
       "2013-10-01 05:10:00                                     0  \n",
       "2013-10-01 05:12:00                                     0  \n",
       "2013-10-01 05:14:00                                     0  \n",
       "\n",
       "[74019 rows x 5 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.to_csv(\"XGBoost_Classified_Appliance_Prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_df= pd.DataFrame({\"Target\":y_test}, index=y_test.index)\n",
    "act_df[\"Appliance_Binary_data\"]=act_df.apply(lambda row: get_binary(row.Target, len(channel_list)), axis=1)\n",
    "actual_df=pd.DataFrame(act_df[\"Appliance_Binary_data\"].to_list(), columns=channel_list, index=act_df.index)\n",
    "actual_df=actual_df.rename(columns=labels_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tv_dvd_digibox_lamp</th>\n",
       "      <th>kettle_radio</th>\n",
       "      <th>gas_boiler</th>\n",
       "      <th>freezer</th>\n",
       "      <th>washing_machine_microwave_breadmaker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-06-20 09:58:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-20 10:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-20 10:02:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-20 10:04:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-20 10:06:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:06:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:10:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:12:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 05:14:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74019 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tv_dvd_digibox_lamp  kettle_radio  gas_boiler  freezer  \\\n",
       "Timestamp                                                                     \n",
       "2013-06-20 09:58:00                    0             0           0        1   \n",
       "2013-06-20 10:00:00                    0             0           0        1   \n",
       "2013-06-20 10:02:00                    0             0           0        1   \n",
       "2013-06-20 10:04:00                    0             0           0        0   \n",
       "2013-06-20 10:06:00                    0             0           0        0   \n",
       "...                                  ...           ...         ...      ...   \n",
       "2013-10-01 05:06:00                    0             0           0        1   \n",
       "2013-10-01 05:08:00                    0             0           0        1   \n",
       "2013-10-01 05:10:00                    0             0           0        1   \n",
       "2013-10-01 05:12:00                    0             0           0        1   \n",
       "2013-10-01 05:14:00                    0             0           0        1   \n",
       "\n",
       "                     washing_machine_microwave_breadmaker  \n",
       "Timestamp                                                  \n",
       "2013-06-20 09:58:00                                     0  \n",
       "2013-06-20 10:00:00                                     0  \n",
       "2013-06-20 10:02:00                                     0  \n",
       "2013-06-20 10:04:00                                     0  \n",
       "2013-06-20 10:06:00                                     0  \n",
       "...                                                   ...  \n",
       "2013-10-01 05:06:00                                     0  \n",
       "2013-10-01 05:08:00                                     0  \n",
       "2013-10-01 05:10:00                                     0  \n",
       "2013-10-01 05:12:00                                     0  \n",
       "2013-10-01 05:14:00                                     0  \n",
       "\n",
       "[74019 rows x 5 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for column in actual_df:\n",
    "    dict_app={}\n",
    "    dict_app[\"Appliance\"]= column\n",
    "    dict_app['Accuracy'] = accuracy_score(actual_df[column], predicted_df[column]) \n",
    "    dict_app['Precision'] = precision_score(actual_df[column], predicted_df[column], average=\"macro\")\n",
    "    dict_app['Recall'] = recall_score(actual_df[column], predicted_df[column], average=\"macro\")\n",
    "    dict_app['F1'] = f1_score(actual_df[column], predicted_df[column], average=\"macro\")\n",
    "    results.append(dict_app)       \n",
    "metrics = pd.DataFrame(results)\n",
    "metrics = metrics.set_index(\"Appliance\")\n",
    "# metrics.index.name= metrics[\"Appliance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Appliance</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tv_dvd_digibox_lamp</th>\n",
       "      <td>0.963280</td>\n",
       "      <td>0.704470</td>\n",
       "      <td>0.648308</td>\n",
       "      <td>0.671384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kettle_radio</th>\n",
       "      <td>0.994961</td>\n",
       "      <td>0.679040</td>\n",
       "      <td>0.614267</td>\n",
       "      <td>0.639391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gas_boiler</th>\n",
       "      <td>0.881693</td>\n",
       "      <td>0.662519</td>\n",
       "      <td>0.794214</td>\n",
       "      <td>0.700029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freezer</th>\n",
       "      <td>0.835785</td>\n",
       "      <td>0.748089</td>\n",
       "      <td>0.766679</td>\n",
       "      <td>0.756537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washing_machine_microwave_breadmaker</th>\n",
       "      <td>0.996177</td>\n",
       "      <td>0.658345</td>\n",
       "      <td>0.615319</td>\n",
       "      <td>0.633409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Accuracy  Precision    Recall        F1\n",
       "Appliance                                                                    \n",
       "tv_dvd_digibox_lamp                   0.963280   0.704470  0.648308  0.671384\n",
       "kettle_radio                          0.994961   0.679040  0.614267  0.639391\n",
       "gas_boiler                            0.881693   0.662519  0.794214  0.700029\n",
       "freezer                               0.835785   0.748089  0.766679  0.756537\n",
       "washing_machine_microwave_breadmaker  0.996177   0.658345  0.615319  0.633409"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_csv(\"House_\"+house+\"_XGBoost_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding recommendations related variables\n",
    "house = 'House_2'\n",
    "min_support = 0.02\n",
    "min_confidence = 0.02\n",
    "considered_rules = 200\n",
    "resampling_time_in_min = '30'\n",
    "rule_files_dir = \"./Rule_Files/\" + house + \"/\"\n",
    "recommendations_file = \"./Recommendations/\" + house + \"/recommendations_\" + str(min_support) + \"_\" + str(min_confidence) + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df['Timestamp'] = list(predicted_df.index)\n",
    "resampled_recs_data = resampling(predicted_df, \"30min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data_dict = dict()\n",
    "\n",
    "for index, row in resampled_recs_data.iterrows():\n",
    "    for column in resampled_recs_data:\n",
    "        if(column == 'Timestamp'):\n",
    "            continue\n",
    "        if column not in channel_data_dict:\n",
    "            channel_data_dict[column] = []\n",
    "        if(row[column] > 0.5):\n",
    "            channel_data_dict[column].append(str(row.Timestamp))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = list(resampled_recs_data['Timestamp'])[0].date()\n",
    "max_date = list(resampled_recs_data['Timestamp'])[-1].date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dates = get_dates_list(min_date, max_date)\n",
    "Time = get_all_times_of_day(\"30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriori_dt = data_extractor(channel_list, channel_data_dict, Dates, Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate frequent itemsets and rules one time slice at a time and save them in a dictionary. \n",
    "\n",
    "time_itemset_map = dict()\n",
    "time_rules_map = dict()\n",
    "time_channels_map_from_itemsets = dict()\n",
    "time_channels_map_from_rules = dict()\n",
    "\n",
    "time_appliance_map = divide_data_into_time(Time, apriori_dt)\n",
    "\n",
    "for timestamp in list(time_appliance_map.keys()):\n",
    "    \n",
    "    print(\"Generating Itemsets for : \" + str(timestamp))\n",
    "    # Generate frequent itemsets\n",
    "    time_itemset_map[timestamp] = get_support_and_itemsets(time_appliance_map[timestamp], min_support)\n",
    "    \n",
    "#     print(\"Generating Rules for : \" + str(timestamp))\n",
    "    # Generate rules\n",
    "    time_rules_map[timestamp] = association_rules(time_itemset_map[timestamp], metric=\"confidence\", min_threshold = min_confidence)\n",
    "#     print(time_rules_map[timestamp].shape)\n",
    "    \n",
    "#     print(\"Filtering Rules for : \" + str(timestamp))\n",
    "    # Filter rules which starts from current time slice\n",
    "    rules_df = time_rules_map[timestamp]\n",
    "    time_rules_map[timestamp] = rules_df[rules_df['antecedents'] == frozenset({timestamp})]\n",
    "    \n",
    "    # Get channels from frequent itemsets\n",
    "    time_channels_map_from_itemsets[timestamp] = get_channels_from_frequent_itemsets(time_itemset_map[timestamp])\n",
    "    \n",
    "    # Get channels from rules\n",
    "    time_channels_map_from_rules[timestamp] = get_channels_from_rules(time_rules_map[timestamp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for timestamp, df in time_rules_map.items():\n",
    "    df.to_csv(rule_files_dir + timestamp + \".csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_list = []\n",
    "for timestamp in Time:\n",
    "    rule_df = time_rules_map[timestamp].sort_values(by=['confidence'], ascending=False)\n",
    "    recommended_channels = get_channels_from_rules(rule_df[:considered_rules])\n",
    "    recommendations = get_appliances_from_channels(recommended_channels, labels_df)\n",
    "    recommendations = change_names(recommendations, show_name_dict)\n",
    "    recommendation_list.append(\",\".join(appliance for appliance in recommendations))\n",
    "time_recommendation_df = pd.DataFrame({\"Time\" : Time, \"Recommendations\" : recommendation_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_recommendation_df.to_csv(recommendations_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
